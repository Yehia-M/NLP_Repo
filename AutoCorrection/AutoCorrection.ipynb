{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        A file_name which is found in your current directory. You just have to read it in. \n",
    "    Output: \n",
    "        words: a list containing all the words in the corpus (text file you read) in lower case. \n",
    "    \"\"\"\n",
    "    words = []\n",
    "    with open(file_name) as file:\n",
    "        data = file.read()\n",
    "        lowerCase = data.lower()\n",
    "        words = re.findall('\\w+', lowerCase)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6116 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "word_l = process_data('shakespeare.txt')\n",
    "vocab = set(word_l)\n",
    "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32198 unique words in the second vocabulary.\n"
     ]
    }
   ],
   "source": [
    "word_2 = process_data('big.txt')\n",
    "vocab2 = set(word_2)\n",
    "print(f\"There are {len(vocab2)} unique words in the second vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word_l):\n",
    "    '''\n",
    "    Input:\n",
    "        word_l: a set of words representing the corpus. \n",
    "    Output:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    '''\n",
    "    word_count_dict = {}  \n",
    "    for word in word_l:\n",
    "        word_count_dict[word] = word_count_dict.get(word,0)+1\n",
    "        \n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6116 key values pairs in first dictionary\n",
      "There are 32198 key values pairs in second dictionary\n"
     ]
    }
   ],
   "source": [
    "word_count_dict = get_count(word_l)\n",
    "print(f\"There are {len(word_count_dict)} key values pairs in first dictionary\")\n",
    "word_count_dict2 = get_count(word_2)\n",
    "print(f\"There are {len(word_count_dict2)} key values pairs in second dictionary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(word_count_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    '''\n",
    "    probs = {}\n",
    "    m = sum(word_count_dict.values())\n",
    "    for word,count in word_count_dict.items():\n",
    "        probs[word] = count/m\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = get_probs(word_count_dict)\n",
    "probs2 = get_probs(word_count_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the string/word for which you will generate all possible words \n",
    "                in the vocabulary which have 1 missing character\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    '''\n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    delete_l = [L+R[1:] for L,R in split_l if R]\n",
    "    \n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "    return delete_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent charater switched\n",
    "    ''' \n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "\n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    switch_l = [L[:-1]+R[0]+L[-1]+R[1:] for L,R in split_l if R and L]\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "    return switch_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
    "    ''' \n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_set = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    replace_set = [ L[:-1] + c + R for L,R in split_l if L for c in letters if c != L[-1]]\n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    ''' \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "\n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    insert_l = [ L + c + R for L,R in split_l for c in letters]\n",
    "\n",
    "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_one_set = set()\n",
    "    f1 = []\n",
    "    f2 = []\n",
    "    f3 = []\n",
    "    f4 = []\n",
    "\n",
    "    f1 = insert_letter(word, verbose=False)\n",
    "    f2 = replace_letter(word, verbose=False)\n",
    "    f3 = delete_letter(word, verbose=False)\n",
    "    if allow_switches:\n",
    "        f4 = switch_letter(word, verbose=False)\n",
    "    edit_one_set = set(f1+f2+f3+f4)    \n",
    "    \n",
    "    return edit_one_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letters(word, allow_switches = True):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        edit_two_set: a set of strings with all possible two edits\n",
    "    '''\n",
    "    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "    oneL = edit_one_letter(word, allow_switches = True)\n",
    "    for i in oneL: \n",
    "        edit_two_set = set(edit_one_letter(i, allow_switches = True)) | edit_two_set\n",
    "    \n",
    "    return edit_two_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
    "    '''\n",
    "    Input: \n",
    "        word: a user entered string to check for suggestions\n",
    "        probs: a dictionary that maps each word to its probability in the corpus\n",
    "        vocab: a set containing all the vocabulary\n",
    "        n: number of possible word corrections you want returned in the dictionary\n",
    "    Output: \n",
    "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
    "    '''\n",
    "    \n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    set_1 = edit_one_letter(word, allow_switches = True)\n",
    "    set_2 = edit_two_letters(word, allow_switches = True)\n",
    "    if word in vocab:\n",
    "        suggestions.append((word,probs[word]))\n",
    "    else:\n",
    "        suggestions = [(i,probs[i]) for i in set_1 if i in vocab] or [(i,probs[i]) for i in set_2 if i in vocab] or [(word,0)]\n",
    "    n_best = sorted(suggestions, key = lambda x : x[-1], reverse = True)[:n]            \n",
    "    \n",
    "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered word =  helol \n",
      "suggestions =  [('hell', 0.0001678666020069385)]\n",
      "word 0: hell, probability 0.000168\n"
     ]
    }
   ],
   "source": [
    "# Test the implementation\n",
    "my_word = 'helol' \n",
    "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) # keep verbose=True\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered word =  helo1 \n",
      "suggestions =  [('hero', 4.9301487560338295e-05), ('hell', 3.585562731660967e-06), ('below', 0.0001030849285352528), ('helps', 4.481953414576209e-06), ('hello', 8.963906829152417e-07), ('felon', 8.963906829152417e-07), ('helm', 8.963906829152417e-07), ('helen', 5.378344097491451e-06), ('help', 0.0002061698570705056), ('halo', 2.6891720487457255e-06), ('held', 0.0002572641259966744), ('melon', 7.171125463321934e-06)]\n",
      "word 0: held, probability 0.000257\n",
      "word 1: help, probability 0.000206\n"
     ]
    }
   ],
   "source": [
    "# Test the implementation\n",
    "my_word = 'helo1' \n",
    "tmp_corrections = get_corrections(my_word, probs2, vocab2, 2, verbose=True) # keep verbose=True\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
